{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjE7N_ZZLg9g"
      },
      "source": [
        "# **Guided LAB -343.4.2 -  How to merge Pandas DataFrames by multiple columns.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYMcP_bzXyTo"
      },
      "source": [
        "## **Lab Objective:**\n",
        "\n",
        "This lab focuses on merging Pandas DataFrames using the pd.merge() function, specifically on merging by multiple columns. You will learn how to merge DataFrames when column names are the same and when they are different, and how to handle duplicate keys during merging. The lab covers various scenarios with practical examples and explanations.\n",
        "\n",
        "**Key Concepts**\n",
        "\n",
        "- `**pd.merge() Function:**`Understanding the syntax and usage of the pd.merge() function for merging DataFrames.\n",
        "- **Merging by Multiple Columns:** Specifying multiple columns as keys for merging using the on parameter.\n",
        "- **Handling Different Column Names**: Merging DataFrames with different column names using left_on and right_on parameters.\n",
        "- **Duplicate Keys:** Identifying and handling duplicate keys during merging using the validate parameter..\n",
        "\n",
        "## **Learning Objectives:**\n",
        "\n",
        "By completing this lab, you will gain hands-on experience in merging Pandas DataFrames by multiple columns, which is a crucial skill for data manipulation and analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfs5aFx-XQkT"
      },
      "source": [
        "### **Introduction:**\n",
        "\n",
        "- The **pandas.merge()** function merge two DataFrames based on a common column or index. It resembles SQL’s JOIN operation and offers more control over how DataFrames are combined.\n",
        "- Using merge() function you can do merging by columns, merging by index, merging on multiple columns, and different join types. By default, it merges on all common columns that exist on both DataFrames and performs an inner join.\n",
        "\n",
        "- The syntax for the pandas.merge() function is:\n",
        "\n",
        "\n",
        "```\n",
        "pd.merge(\n",
        "    left,\n",
        "    right,\n",
        "    how=\"inner\",\n",
        "    on=None,\n",
        "    left_on=None,\n",
        "    right_on=None,\n",
        "    left_index=False,\n",
        "    right_index=False,\n",
        "    sort=True,\n",
        "    suffixes=(\"_x\", \"_y\"),\n",
        "    copy=True,\n",
        "    indicator=False,\n",
        "    validate=None,\n",
        ")\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E0bKhNxZFsB"
      },
      "source": [
        "**Let’s create two DataFrames and run the above examples to understand pandas join.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMSvs5YIXGDV",
        "outputId": "a548e09c-6c67-4e00-f217-28c96617f401"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First DataFrame:\n",
            "    Courses    Fee Duration\n",
            "0    Spark  20000    30day\n",
            "1  PySpark  25000   40days\n",
            "2   Python  30000   60days\n",
            "3   pandas  24000   55days\n",
            "4     Java  40000   50days\n",
            "Second DataFrame:\n",
            "     Courses    Fee Percentage\n",
            "0      Java  20000        10%\n",
            "1   PySpark  25000        20%\n",
            "2    Python  30000        25%\n",
            "3    pandas  24000        20%\n",
            "4  Hyperion  40000        10%\n",
            "5      html   4000        50%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create Pandas DataFrame\n",
        "import pandas as pd\n",
        "left_df = pd.DataFrame({'Courses': [\"Spark\",\"PySpark\",\"Python\",\"pandas\",\"Java\"],\n",
        "                    'Fee' : [20000,25000,30000,24000,40000],\n",
        "                    'Duration':['30day','40days','60days','55days','50days']})\n",
        "\n",
        "right_df = pd.DataFrame({'Courses': [\"Java\",\"PySpark\",\"Python\",\"pandas\",\"Hyperion\",\"html\"],\n",
        "                    'Fee': [20000,25000,30000,24000,40000,4000],\n",
        "                    'Percentage':['10%','20%','25%','20%','10%','50%']})\n",
        "\n",
        "print(\"First DataFrame:\\n\", left_df)\n",
        "print(\"Second DataFrame:\\n\", right_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTWeW6djZnza"
      },
      "source": [
        "## **Example: Merge default pandas DataFrame without any key column**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lbOrmc6aTP7"
      },
      "source": [
        "You can pass two DataFrames to be merged into the pandas.merge() function. This function collects all common columns in both DataFrames and replaces each common column in both DataFrames with a single one. It merges the DataFrames df and df1 assigned to merged_df.\n",
        "\n",
        "By default, the merge() function applies join contains on all columns that are present on both DataFrames and uses inner join. We have the columns Courses and Fee common to both the DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "L9rfQ0PNZmoy",
        "outputId": "674ca815-cc05-4266-d12b-7a068ca4ac3a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Courses</th>\n",
              "      <th>Fee</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PySpark</td>\n",
              "      <td>25000</td>\n",
              "      <td>40days</td>\n",
              "      <td>20%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Python</td>\n",
              "      <td>30000</td>\n",
              "      <td>60days</td>\n",
              "      <td>25%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pandas</td>\n",
              "      <td>24000</td>\n",
              "      <td>55days</td>\n",
              "      <td>20%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Courses    Fee Duration Percentage\n",
              "0  PySpark  25000   40days        20%\n",
              "1   Python  30000   60days        25%\n",
              "2   pandas  24000   55days        20%"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df = pd.merge(left_df,right_df)\n",
        "merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VULR-ziaYDK",
        "outputId": "ddcb1800-26d5-43e6-e825-a772220df22f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 4)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KJ8KEd5bpNC"
      },
      "source": [
        "## **Example: Pandas Merge DataFrames Based on single Columns**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCflGhmCfXLD"
      },
      "source": [
        "If you want to merge DataFrames based on a single key column, you can simply pass the column name as a string to the on parameter. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvKdQkL7ZA4N",
        "outputId": "8e1c5e24-cea0-4554-b55f-ed7f21035052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Courses  Fee_x Duration  Fee_y Percentage\n",
            "0  PySpark  25000   40days  25000        20%\n",
            "1   Python  30000   60days  30000        25%\n",
            "2   pandas  24000   55days  24000        20%\n",
            "3     Java  40000   50days  20000        10%\n"
          ]
        }
      ],
      "source": [
        "result = pd.merge(left_df, right_df, on=\"Courses\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xEpYcqZc9yN",
        "outputId": "762aaaac-6559-4fd6-fe81-eac6fbf2c6dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 5)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gaMGWite0gr"
      },
      "source": [
        "##**Example: Use pandas.merge() to Multiple Columns**\n",
        "\n",
        "You can also explicitly specify the column names you want to use for joining. To specify column names use on param of the merge() function. This also takes a list of names when you want to merge multiple columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlRTlqP7fAvC",
        "outputId": "434ee774-d489-44a5-f363-fb1056046853"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After merging the DataFrames:\n",
            "    Courses    Fee Duration Percentage\n",
            "0  PySpark  25000   40days        20%\n",
            "1   Python  30000   60days        25%\n",
            "2   pandas  24000   55days        20%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Use pandas.merge() on multiple columns\n",
        "df_result = pd.merge(left_df,right_df, on=['Courses','Fee'])\n",
        "print(\"After merging the DataFrames:\\n\", df_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lDRtry8fPV7",
        "outputId": "83842d7c-309c-4b95-8b22-d9819b9d0400"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 4)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_result.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adz0_Bo2eCYi"
      },
      "source": [
        "## **Example:  Use pandas.merge() when Column Names Different**\n",
        "When you have column names on the left and right that are different and want to use these as a join column, use left_on and right_on parameters.\n",
        "\n",
        "This also takes a list of column names as values to merge on multiple columns.\n",
        "\n",
        "The left_on will be set to the name of the column in the left DataFrame and right_on will be set to the name of the column in the right DataFrame.\n",
        "\n",
        "This also takes a list of names when you want to merge multiple columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUrHGV88bvgB",
        "outputId": "2d57f7a9-3135-426f-d31c-f9b9bca6fc51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After merging the DataFrames:\n",
            "    Courses    Fee Duration Percentage\n",
            "0    Spark  20000    30day        NaN\n",
            "1  PySpark  25000   40days        20%\n",
            "2   Python  30000   60days        25%\n",
            "3   pandas  24000   55days        20%\n",
            "4     Java  40000   50days        NaN\n"
          ]
        }
      ],
      "source": [
        "result = pd.merge(left_df, right_df, how='left', left_on=['Courses','Fee'], right_on = ['Courses','Fee'])\n",
        "print(\"After merging the DataFrames:\\n\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vWBPtEldMBT",
        "outputId": "c55e8991-ef52-4dcf-ef1a-799b0c405073"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5, 4)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpmuF3ATfuot"
      },
      "source": [
        "# **Example: Checking for duplicate keys**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0uiYyPGf07C"
      },
      "source": [
        "- We can use the validate argument to automatically check whether there are unexpected duplicates in their merge keys. Key uniqueness is checked before merge operations and so should protect against memory overflows. Checking key uniqueness is also a good way to ensure user data structures are as expected.\n",
        "\n",
        "- In the following example, there are duplicate values of B in the right DataFrame. As this is not a one-to-one merge – as specified in the validate argument – an exception will be raised."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "u7zvz6YOgIxi",
        "outputId": "0c49f0da-8a40-481b-ea6f-bee7967ac9d2"
      },
      "outputs": [
        {
          "ename": "MergeError",
          "evalue": "Merge keys are not unique in right dataset; not a one-to-one merge",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mMergeError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m left = pd.DataFrame({\u001b[33m\"\u001b[39m\u001b[33mA\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m]})\n\u001b[32m      3\u001b[39m right = pd.DataFrame({\u001b[33m\"\u001b[39m\u001b[33mA\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m6\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m]})\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m result = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mB\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minner\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mone_to_one\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juan.hun\\OneDrive - PeopleShores PBC\\Desktop\\python_practice\\venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:170\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[32m    156\u001b[39m         left_df,\n\u001b[32m    157\u001b[39m         right_df,\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         copy=copy,\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     op = \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result(copy=copy)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juan.hun\\OneDrive - PeopleShores PBC\\Desktop\\python_practice\\venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:813\u001b[39m, in \u001b[36m_MergeOperation.__init__\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    809\u001b[39m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[32m    810\u001b[39m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[32m    811\u001b[39m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m813\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_validate_kwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juan.hun\\OneDrive - PeopleShores PBC\\Desktop\\python_practice\\venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1657\u001b[39m, in \u001b[36m_MergeOperation._validate_validate_kwd\u001b[39m\u001b[34m(self, validate)\u001b[39m\n\u001b[32m   1653\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[32m   1654\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMerge keys are not unique in left dataset; not a one-to-one merge\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1655\u001b[39m         )\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m right_unique:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[32m   1658\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMerge keys are not unique in right dataset; not a one-to-one merge\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1659\u001b[39m         )\n\u001b[32m   1661\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m validate \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mone_to_many\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1:m\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m left_unique:\n",
            "\u001b[31mMergeError\u001b[39m: Merge keys are not unique in right dataset; not a one-to-one merge"
          ]
        }
      ],
      "source": [
        "left = pd.DataFrame({\"A\": [1, 2], \"B\": [1, 2]})\n",
        "\n",
        "right = pd.DataFrame({\"A\": [4, 5, 6], \"B\": [2, 2, 2]})\n",
        "\n",
        "result = pd.merge(left, right, on=\"B\", how=\"inner\", validate=\"one_to_one\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90TvHpBJgyIa"
      },
      "source": [
        "## We are aware of the duplicates in the right DataFrame but wants to ensure there are no duplicates in the left DataFrame, we can use the **validate='one_to_many'** argument instead, which will not raise an exception."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OcdVf7OgR4S",
        "outputId": "9295084d-5d64-4136-b517-d2d45a819f72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   A_x  B  A_y\n",
            "0    2  2    4\n",
            "1    2  2    5\n",
            "2    2  2    6\n"
          ]
        }
      ],
      "source": [
        "result = pd.merge(left, right, on=\"B\", how=\"inner\", validate=\"one_to_many\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP95e_9-kXYV"
      },
      "source": [
        "# **Example: Consider a scenario where you have information about sales transactions and product details, and you want to merge these datasets based on both 'ProductID' and 'StoreID' keys.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY5hekpekZDF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined DataFrame:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>ProductID</th>\n",
              "      <th>StoreID</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>Amount</th>\n",
              "      <th>ProductName</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>500.0</td>\n",
              "      <td>Laptop</td>\n",
              "      <td>Electronics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>102</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>300.0</td>\n",
              "      <td>Headphones</td>\n",
              "      <td>Electronics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>103</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>200.0</td>\n",
              "      <td>Smartphone</td>\n",
              "      <td>Electronics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>101</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>400.0</td>\n",
              "      <td>Laptop</td>\n",
              "      <td>Electronics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>105</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>150.0</td>\n",
              "      <td>Monitor</td>\n",
              "      <td>Electronics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>106</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>Mouse</td>\n",
              "      <td>Electronics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID  ProductID  StoreID  Quantity  Amount ProductName  \\\n",
              "0              1        101        1         5   500.0      Laptop   \n",
              "1              2        102        2         3   300.0  Headphones   \n",
              "2              3        103        1         2   200.0  Smartphone   \n",
              "3              4        101        3         4   400.0      Laptop   \n",
              "4              5        105        2         1   150.0     Monitor   \n",
              "5              6        106        1         1    30.0       Mouse   \n",
              "\n",
              "      Category  \n",
              "0  Electronics  \n",
              "1  Electronics  \n",
              "2  Electronics  \n",
              "3  Electronics  \n",
              "4  Electronics  \n",
              "5  Electronics  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame with sales transactions\n",
        "sales_data = {\n",
        "    'TransactionID': [1, 2, 3, 4, 5, 6],\n",
        "    'ProductID': [101, 102, 103, 101, 105, 106],\n",
        "    'StoreID': [1, 2, 1, 3, 2, 1],\n",
        "    'Quantity': [5, 3, 2, 4, 1, 1],\n",
        "    'Amount': [500.00, 300.00, 200.00, 400.00, 150.00, 30.00]\n",
        "}\n",
        "\n",
        "df_sales = pd.DataFrame(sales_data)\n",
        "\n",
        "# Create a DataFrame with product details\n",
        "products_data = {\n",
        "    'ProductID': [101, 102, 103, 104, 105, 106],\n",
        "    'ProductName': ['Laptop', 'Headphones', 'Smartphone', 'Tablet', 'Monitor', 'Mouse'],\n",
        "    'Category': ['Electronics', 'Electronics', 'Electronics', 'Electronics', 'Electronics', 'Electronics'] # ------------- added all of the last elements from here up\n",
        "}\n",
        "\n",
        "df_products = pd.DataFrame(products_data)\n",
        "\n",
        "# Merge the DataFrames based on 'ProductID' and 'StoreID' keys\n",
        "df_combined = pd.merge(df_sales, df_products, on='ProductID', how='left')\n",
        "\n",
        "# Display the combined DataFrame\n",
        "print(\"Combined DataFrame:\")\n",
        "df_combined"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-n3DVREF64i"
      },
      "source": [
        "# **Submission Instructions:**\n",
        "\n",
        "- Submit your completed lab using the Start Assignment button on the assignment page in Canvas.\n",
        "- Your submission can be include:\n",
        "  - if you are using notebook then, all tasks should be written and submitted in a single notebook file, for example: (**your_name_labname.ipynb**).\n",
        "  - if you are using python script file, all tasks should be written and submitted in a single python script file for example: **(your_name_labname.py)**.\n",
        "- Add appropriate comments and any additional instructions if required.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
